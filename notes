1. Bootstrap with a fast NN trained on lots of good games (OTB/corr/computer)
2. Can have several components to choosing a move: e.g., first exhaustively search for mate in 3, then perform MCTS rollout
3. We can use several different NNs: e.g., a fast one for generating moves during training (bootstrapped and updated), and a large one for the final agent (no need to bootstrap, but can be updated in parallel to the training games). Use the fast NN both for move ordering (bootstrapped) and for position eval (bootstrapped to be something simple like material counting).
4. During training, can we actually use alpha beta search?
5. After training, we may have an alpha beta search and/or an MCTS search
6. Is NNUE only used to eval positions? Not for move ordering?
7. Train NNUE strictly to learn to rank, use it for move ordering?
8. NNUE with additional layers: after the 512->32 layer use a densenet of 32 -> 32 layers such that the total computation time is no more than that of the 512->32 layer. Makes the NN much more powerful for not much more computation time. So e.g. the first layer is 32x32, the next is 32x64, then 32x96, so it's like 32x32*(1+2+3...) or 32x32*(L+1)*L/2, so solving for L to keep that 32x512 or less, we would get L = 5. So, we would replace the 512->32->32->1 NN with a 512->(5 layer densenet with 32 neurons per layer)->1 NN. This is much more powerful while being less than double the calculation time!
9. Julia based humanlike player that uses human rating as input and tries to predict human move, also uses MCTS tree search but has a differentiable, rating dependent prob of early stopping, can also perform a deterministic win search up to a depth or total node count that is also differentiable and rating dependent
10. Move generation: After checks, captures, transition tables and killer moves, we still want to order remaining moves as best as possible. For starters, loop over piece types in order of which are most promising. For each one, loop over moves that are most promising. E.g. for rooks, probably f1f6 is more often promising than f1g1. The problem with this kind of ordering is that some of the moves might be illegal, whereas iterating from closest to furthest allows to skip after hitting an occupied square. So, is there an easy way to tell where in a line the next occupied piece is? I think so using trailz. Also if we have already done captures, we at least know where the enemy piece is (but not our own). Another idea is using pairs of pieces to determine good squares to move either of them, e.g. if the rooks are on d3 and e1 then e1d1 or d3e3 should be high priority move suggestions (doubling rooks). To do this, we would need 32*63 tables of length 28, which is just about 55k ints total. In fact, we should use the rook occupancies to hash into the table. We can use a database to learn to rank these moves, if we define a smooth enough function for them so they generalize. I think we first learn to rank: If no checks or captures available, what is the priority list by piece type? Then, we learn to rank for individual pieces as well as pairs (RBN), what is the priority list for moves? I would guess PNBRQK, but who knows? Another interesting optimization is: Given the types of pieces left by both players, what is the rank? E.g. in RPvR endgames, more likely to move R than P, but in RPvBN endgames perhaps more likely to move P. There are 2^10 possible configurations here, and each can have a rank of no more than 6 ints. Very small. Each one can lookup a list of moves (except pawns, which have to be iterated over, perhaps in central to wing order). We can either iterate over each list exhaustively before moving to the next, or interleave them somehow, e.g., if there are 6 pieces, do 6 of the highest priority, then 5 of the second highest, down to 1 of the lowest, and repeat. Perhaps we decide to prefer moves in the order NBPRQK, then we do 6N5B4P3R2Q1K, 6N.... Alternatively, NNBNBPNBPRNBPRQNBPRQK, NNBNBP.... It seems like this is a really good idea.
